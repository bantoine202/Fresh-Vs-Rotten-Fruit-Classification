<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Fresh vs Rotten Fruit Classification</title>

<style>
    body {
        font-family: Arial, Helvetica, sans-serif;
        margin: 0;
        padding: 0;
        background: #f8f9fb;
        color: #333;
        line-height: 1.6;
    }

    header {
        background: linear-gradient(to right, #ffb347, #ffcc33);
        color: #222;
        padding: 30px 20px;
        text-align: center;
        font-size: 2rem;
        font-weight: bold;
    }

    .container {
        width: 85%;
        max-width: 1100px;
        margin: auto;
        padding: 20px 0;
    }

    h2 {
        color: #333;
        margin-top: 40px;
        border-left: 6px solid #ffb347;
        padding-left: 10px;
    }

    p {
        text-align: justify;
        margin-bottom: 15px;
    }

    img {
        width: 100%;
        max-width: 700px;
        display: block;
        margin: 20px auto;
        border-radius: 10px;
        background:white;
        padding:10px;
        box-shadow:0 4px 12px rgba(0,0,0,0.1);
    }

    .links {
        background: #fff5da;
        padding: 15px;
        border-left: 6px solid #ffb347;
        border-radius: 6px;
        margin-bottom: 30px;
    }

    .links a {
        display: block;
        margin-bottom: 8px;
        font-weight: bold;
        color: #0056b3;
        text-decoration: none;
    }

    footer {
        text-align: center;
        padding: 20px;
        background: #ffe8b5;
        margin-top: 40px;
        font-size: 0.9rem;
    }
</style>

</head>
<body>

<header>Fresh vs Rotten Fruit Classification Using Deep Learning</header>

<div class="container">

    <div class="links">
        <strong>Student:</strong> Britney Antoine<br>
        <strong>Course:</strong> Mathematics of Data Science<br><br>

        <a href="https://github.com/bantoine202/Fresh-Vs-Rotten-Fruit-Classification" target="_blank">
            GitHub Repository
        </a>

        <a href="https://colab.research.google.com/drive/1XLLu2RoeWz_1GWljQrs06QHmbYTOJdFm?usp=sharing" target="_blank">
            Google Colab Notebook
        </a>

        <a href="https://docs.google.com/presentation/d/1-RAHqljiPkCJdO0VfKEnjAP6_sEzp8J7gVczrUA7Uhg/edit?usp=sharing" target="_blank">
            Google Slides Presentation
        </a>

        <a href="https://wandb.ai/bantoine2024-florida-atlantic-university/fresh-vs-rotten-fruit" target="_blank">
            Weights & Biases Project
        </a>
    </div>

    <h2>Abstract</h2>
    <p>
        The goal of this project was to classify images of fruits as fresh or rotten using deep learning.
        A convolutional neural network based on the AlexNet architecture was implemented and trained on a
        real-world image dataset. Multiple controlled experiments were performed to measure the effect of
        batch size, learning rate, data augmentation, and architecture choice on model performance.
        Results show near-perfect classification accuracy, demonstrating that deep learning can reliably
        distinguish freshness without hand-engineered features.
    </p>

    <h2>Problem Statement</h2>
    <p>
        Food waste is a major economic and environmental issue. Automating visual inspection of produce
        could help improve safety, reduce waste, and minimize cost. The problem explored here is binary:
        given an image of fruit, predict whether it is fresh or rotten. The task is challenging due to
        variations in size, lighting, color, and viewpoint across images.
    </p>

    <h2>Dataset</h2>
    <p>
        The dataset contains images of fresh and rotten fruits across multiple categories
        (apples, bananas, oranges, etc.). Images were separated into training, validation, and test sets
        and standardized to 224×224 resolution. Data augmentation methods including horizontal flips and
        color jitter were applied to improve generalization. In total, thousands of images were used for
        model training and evaluation.
    </p>

    <h2>Methodology</h2>
    <p>
        AlexNet was implemented in PyTorch with pretrained ImageNet weights. The final classification
        layer was replaced with a 2-class output to allow binary classification. The model was trained
        using cross-entropy loss and the Adam optimizer. Experiments were run and tracked using
        Weights & Biases. 

        Key experiments included:
        (1) comparing batch sizes (16 vs 64),
        (2) testing different learning rates (1e-3 vs 1e-4),
        (3) training with vs. without augmentation,
        (4) comparing AlexNet vs. ResNet18.
    </p>

    <h2>Experimental Results</h2>
    <p>
        Overall training accuracy approached 100% for nearly all configurations within a few epochs,
        while training loss consistently decreased. Models using augmentation showed slightly better
        generalization stability. ResNet18, a deeper architecture, performed competitively but was not
        significantly better than AlexNet due to the binary nature of the task.
    </p>

    <h2>Training Accuracy</h2>
    <img src="images/train_acc.png" alt="Training Accuracy">

    <h2>Training Loss</h2>
    <img src="images/train_loss.png" alt="Training Loss">

    <h2>Confusion Matrix</h2>
    <img src="images/confusion_matrix.png" alt="Confusion Matrix">

    <h2>Discussion</h2>
    <p>
        The results demonstrate that CNN architectures trained with transfer learning can achieve
        extremely high performance on the fresh vs. rotten classification task. The confusion matrix
        shows zero misclassifications, indicating strong feature separation. A notable observation is
        that improvements from changing batch size or learning rate were marginal, suggesting that the
        dataset was readily separable. Data augmentation helped reinforce model robustness to noise,
        although performance was already saturated without it.
    </p>

    <p>
        The high accuracy indicates that visual cues such as color variation, bruising, and texture
        degradation are highly predictive and easily captured by convolutional filters. These findings
        support the feasibility of automated fruit quality assessment systems.
    </p>

    <h2>Conclusion</h2>
    <p>
        This project successfully built a deep learning system capable of classifying fresh vs. rotten
        fruit with near-perfect accuracy. AlexNet proved effective, and ResNet18 did not significantly
        improve results. The success of the model highlights the potential for real-time quality control
        solutions in agriculture, supply chain management, and retail environments.
        Future work could include multi-class classification, defect localization, and deployment on edge
        devices for real-world use.
    </p>

</div>

<footer>
    © 2024 Britney Antoine – Fresh vs Rotten Fruit Classification
</footer>

</body>
</html>
