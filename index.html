<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Fresh vs. Rotten Fruit Classification</title>

<style>
    body {
        font-family: "Helvetica", Arial, sans-serif;
        margin: 0;
        padding: 0;
        background: #f3f5f9;
        color: #222;
        line-height: 1.6;
    }

    header {
        background: linear-gradient(90deg, #ff6a00, #ee0979);
        color: white;
        padding: 50px 20px;
        text-align: center;
    }

    h1, h2, h3 {
        font-weight: 700;
    }

    h2 {
        margin-top: 50px;
    }

    .container {
        width: 90%;
        max-width: 1200px;
        margin: auto;
        padding-bottom: 50px;
    }

    section {
        background: white;
        margin-top: 30px;
        padding: 30px 40px;
        border-radius: 12px;
        box-shadow: 0px 4px 20px rgba(0,0,0,0.08);
    }

    img {
        width: 90%;
        display: block;
        margin: auto;
        border-radius: 8px;
        border: 1px solid #ccc;
    }

    .caption {
        text-align: center;
        font-style: italic;
        font-size: 0.95em;
        color: #444;
        margin-top: 10px;
        margin-bottom: 25px;
    }

    .footer {
        text-align: center;
        padding: 20px;
        margin-top: 50px;
        background-color: #333;
        color: white;
    }

    a {
        color: #ee0979;
        font-weight: bold;
        text-decoration: none;
    }
    a:hover { text-decoration: underline; }

</style>
</head>

<body>

<header>
    <h1>Fresh vs. Rotten Fruit Image Classification</h1>
    <h3>By Britney Antoine | Mathematics of Data Science</h3>
</header>

<div class="container">



<!-- ABSTRACT -->
<section>
    <h2>Abstract</h2>
    <p>
        The goal of this project was to develop a computer vision model using deep learning 
        that can classify fruit images as either <strong>fresh</strong> or <strong>rotten</strong>. 
        I implemented <strong>AlexNet</strong>, conducted multiple experiments, and evaluated performance 
        using metrics such as accuracy, loss, and a confusion matrix. 
        The results demonstrate near-perfect classification performance, showing strong potential for 
        automated quality control in food production and retail environments.
    </p>
</section>



<!-- PROBLEM STATEMENT -->
<section>
    <h2>Problem & Motivation</h2>
    <p>
        Food waste is a major global issue, costing billions of dollars per year and contributing 
        to environmental degradation. Manual inspection of produce is labor-intensive, inefficient, 
        and prone to human error. Computer vision can automate this process, improving accuracy and speed.
    </p>

    <p>
        This project explores whether deep learning models can reliably detect spoiled fruit, 
        potentially supporting applications in agriculture, supply chain management, grocery 
        automation, and smart refrigerators.
    </p>
</section>



<!-- DATASET -->
<section>
    <h2>Dataset</h2>
    <p>
        I used the <strong>Fresh and Rotten Fruit Dataset</strong> from Kaggle, containing thousands of labeled images across two categories:
    </p>

    <ul>
        <li>Fresh fruit</li>
        <li>Rotten fruit</li>
    </ul>

    <p>
        Images were preprocessed and resized to <strong>224×224</strong> for compatibility with AlexNet. 
        Additional augmentation (random flips, rotations, color jitter) was applied to simulate real-world variability.
    </p>
</section>



<!-- METHODS -->
<section>
    <h2>Methodology</h2>
    <p>
        The core model used in this project was <strong>AlexNet</strong>, a classic CNN architecture known for strong performance 
        on image classification tasks. I modified the final layer to output two classes: fresh and rotten.
    </p>

    <p>Key steps:</p>
    <ul>
        <li>Implement AlexNet with transfer learning</li>
        <li>Split data into train/validation sets</li>
        <li>Experiment with batch size, learning rate, and augmentation</li>
        <li>Track metrics using <strong>Weights & Biases</strong></li>
    </ul>

    <p>
        In addition, I compared performance to <strong>ResNet18</strong>, a deeper residual network, 
        to test whether model complexity improved results.
    </p>
</section>



<!-- EXPERIMENTS -->
<section>
    <h2>Experiments</h2>
    <p>To understand model behaviors, I ran four major experiments:</p>
    <ul>
        <li><strong>Batch size comparison:</strong> 16 vs. 64</li>
        <li><strong>Learning rate comparison:</strong> 1e-3 vs. 1e-4</li>
        <li><strong>Data augmentation:</strong> with vs. without</li>
        <li><strong>Architecture comparison:</strong> AlexNet vs. ResNet18</li>
    </ul>

    <p>
        All experiments were tracked via W&B dashboards for analysis.
    </p>
</section>



<!-- RESULTS -->
<section>
    <h2>Results & Visualizations</h2>

    <h3>Training Loss Curves</h3>
    <img src="images/loss.png" alt="Training Loss Chart">
    <p class="caption">
        Training loss decreased rapidly during early epochs, indicating fast convergence for all models. 
        Loss values remained low and stable, suggesting models generalized well and did not overfit.
    </p>

    <h3>Training Accuracy Curves</h3>
    <img src="images/accuracy.png" alt="Training Accuracy Chart">
    <p class="caption">
        Training accuracy reached approximately 99–100% across all experiments, regardless of model, batch size, 
        or learning rate. ResNet18 and augmented AlexNet runs converged slightly faster.
    </p>

    <h3>Confusion Matrix</h3>
    <img src="images/confusion_matrix.png" alt="Confusion Matrix">
    <p class="caption">
        The final model achieved perfect classification on the validation set, correctly identifying every sample 
        of fresh and rotten fruit. This confirms the model's strong ability to separate features between classes.
    </p>

</section>



<!-- DISCUSSION -->
<section>
    <h2>Discussion</h2>
    <p>
        Results show that both AlexNet and ResNet18 performed extremely well on this dataset, likely due to
        clearly visible differences between fresh and rotten fruit images. Augmentation helped reduce loss early on, 
        but did not significantly alter the final accuracy.
    </p>

    <p>
        The perfect confusion matrix suggests either unusually clean data or potential class imbalance. 
        Future work should include:
    </p>

    <ul>
        <li>Testing on noisy or real-world images</li>
        <li>Evaluating robustness under low lighting or occlusion</li>
        <li>Exploring multi-class classification (apple, banana, etc.)</li>
        <li>Deploying to a web or mobile prototype</li>
    </ul>
</section>



<!-- CONCLUSION -->
<section>
    <h2>Conclusion</h2>
    <p>
        This project successfully demonstrated that deep learning models can classify 
        fresh versus rotten fruit with extremely high accuracy. The models trained quickly, 
        converged efficiently, and generalized well. These results support the potential 
        use of automated visual inspection systems in real-world food processing environments.
    </p>
</section>



<!-- LINKS -->
<section>
    <h2>Project Links</h2>

    <p><strong>GitHub Repository:</strong> <a href="https://github.com/bantoine202/Fresh-Vs-Rotten-Fruit-Classification" target="_blank">
        github.com/bantoine202/Fresh-Vs-Rotten-Fruit-Classification</a></p>

    <p><strong>Google Colab Notebook:</strong> <a href="https://colab.research.google.com/drive/1XLLu2RoeWz_1GWljQrs06QHmbYTOJdFm?usp=sharing" target="_blank">
        Open in Colab</a></p>

    <p><strong>Google Slides Presentation:</strong> <a href="https://docs.google.com/presentation/d/1-RAHqljiPkCJdO0VfKEnjAP6_sEzp8J7gVczrUA7Uhg/edit?usp=sharing" target="_blank">
        View Slides</a></p>
</section>


</div>


<footer class="footer">
    © 2024 Britney Antoine | Fresh vs Rotten Fruit Classification
</footer>

</body>
</html>
